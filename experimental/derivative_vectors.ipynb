{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427131c9-643a-483b-a961-0f2ef545e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "827cd641-49c9-4d09-87e7-18d53ea84423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessor.preprocessing import FileIO\n",
    "from src.pipelines.pipeline import create_dataset, create_vectors\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935b509f-cca0-4508-bfc4-6636e884d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/huberman_labs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a86c0c5-394b-47d3-b029-aec70b4cc0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FileIO().load_json(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18bf16a4-8a8f-4342-9449-bf35deddb0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/openai/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0c74e19-89c4-41d5-aa66-6e8ae098f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [d['summary'] for d in data]\n",
    "sum_matrix = model.encode(summaries, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e55e2caf-32c1-4311-a9b0-e99c524a8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(data):\n",
    "    d['summary_embedding'] = sum_matrix[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae9803d-8739-46b6-bd65-9e87c35cb005",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "59849bb7-905c-4a5b-a7a3-43fb4674c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'Testosterone replacement therapy'\n",
    "topic_vector = model.encode(topic, convert_to_tensor=True).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b5ad0f0a-0408-45f1-8f3d-aace5c20f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tensor = cos_sim(sum_matrix, topic_vector).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1665a96c-f557-4fe7-b5b2-9dd758f53c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_answer_tensor = answer_tensor.squeeze().argsort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "38930ecd-da05-4be3-96c1-afd6a7f419b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_titles(indexes: list[int], data: list[dict]) -> list[str]:\n",
    "    indexes = indexes.tolist()\n",
    "    return [data[i]['title'] for i in indexes]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "44483dac-6af5-4589-9c49-d09fb1c7d6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr. Kyle Gillett: Tools for Hormone Optimization in Males | Huberman Lab Podcast 102',\n",
       " 'Dr. Michael Eisenberg: Improving Male Sexual Health, Function & Fertility',\n",
       " 'Dr. Duncan French: How to Exercise for Strength Gains & Hormone Optimization | Huberman Lab #45',\n",
       " 'Dr. Kyle Gillett: How to Optimize Your Hormones for Health & Vitality | Huberman Lab Podcast #67',\n",
       " 'The Science of How to Optimize Testosterone & Estrogen',\n",
       " 'Biological Influences On Sex, Sex Differences & Preferences',\n",
       " 'Understanding & Controlling Aggression | Huberman Lab Podcast #71']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grab_titles(sorted_answer_tensor[:7], data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "31778aa7-37c3-4cbb-921e-f30d57e9bac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([ 0.5858,  0.4801,  0.4113,  0.4095,  0.4090,  0.3695,  0.3602,  0.3415,\n",
       "         0.3174,  0.3154,  0.3100,  0.2865,  0.2819,  0.2809,  0.2752,  0.2750,\n",
       "         0.2735,  0.2693,  0.2659,  0.2547,  0.2542,  0.2515,  0.2487,  0.2413,\n",
       "         0.2412,  0.2408,  0.2393,  0.2390,  0.2384,  0.2359,  0.2355,  0.2305,\n",
       "         0.2281,  0.2279,  0.2257,  0.2252,  0.2224,  0.2191,  0.2156,  0.2124,\n",
       "         0.2118,  0.2109,  0.2097,  0.2091,  0.2066,  0.2060,  0.2059,  0.2043,\n",
       "         0.2011,  0.2009,  0.1993,  0.1983,  0.1968,  0.1954,  0.1901,  0.1900,\n",
       "         0.1861,  0.1851,  0.1838,  0.1831,  0.1815,  0.1804,  0.1791,  0.1740,\n",
       "         0.1739,  0.1727,  0.1717,  0.1703,  0.1698,  0.1679,  0.1634,  0.1597,\n",
       "         0.1594,  0.1579,  0.1574,  0.1559,  0.1545,  0.1544,  0.1540,  0.1532,\n",
       "         0.1499,  0.1472,  0.1447,  0.1432,  0.1420,  0.1419,  0.1419,  0.1412,\n",
       "         0.1408,  0.1379,  0.1375,  0.1360,  0.1353,  0.1301,  0.1286,  0.1285,\n",
       "         0.1271,  0.1270,  0.1254,  0.1247,  0.1238,  0.1235,  0.1212,  0.1199,\n",
       "         0.1195,  0.1193,  0.1182,  0.1181,  0.1161,  0.1137,  0.1105,  0.1076,\n",
       "         0.1064,  0.1040,  0.1017,  0.1002,  0.0979,  0.0977,  0.0951,  0.0937,\n",
       "         0.0903,  0.0881,  0.0875,  0.0874,  0.0846,  0.0839,  0.0836,  0.0832,\n",
       "         0.0822,  0.0814,  0.0809,  0.0793,  0.0780,  0.0743,  0.0723,  0.0706,\n",
       "         0.0702,  0.0680,  0.0674,  0.0670,  0.0664,  0.0661,  0.0648,  0.0624,\n",
       "         0.0621,  0.0621,  0.0619,  0.0614,  0.0593,  0.0565,  0.0562,  0.0561,\n",
       "         0.0519,  0.0502,  0.0501,  0.0491,  0.0489,  0.0482,  0.0451,  0.0430,\n",
       "         0.0428,  0.0417,  0.0416,  0.0366,  0.0344,  0.0327,  0.0322,  0.0318,\n",
       "         0.0287,  0.0252,  0.0234,  0.0223,  0.0218,  0.0195,  0.0183,  0.0161,\n",
       "         0.0145,  0.0125,  0.0084,  0.0081,  0.0038,  0.0019,  0.0007, -0.0064,\n",
       "        -0.0081, -0.0186, -0.0206, -0.0272, -0.0273, -0.0284, -0.0350, -0.0492,\n",
       "        -0.0987]),\n",
       "indices=tensor([ 90,  28, 147, 125, 177, 178, 121,  46, 157,  81,  99,  67,  83,  18,\n",
       "         74,  98, 174,   1, 112, 101, 153,  57, 144, 107, 103, 158, 170,  76,\n",
       "         79, 127,  27, 175, 140,  49, 123, 171,  29,  39, 113,  88,   6, 117,\n",
       "        159,  70,  93,  82,  30,  60, 133,  52,  69,  14, 143,  47, 110, 114,\n",
       "          9, 169,  33, 176,  15,  63,  84, 166, 155, 183, 132,  86, 152, 180,\n",
       "         16, 189,  95, 100,  25, 122, 154, 192,  68, 139, 173, 134,  77, 126,\n",
       "        182,  62,  53,  17,  61,  41, 124, 129,  66,  26, 148, 179,  20, 185,\n",
       "        187, 145, 120, 190,  80,  37, 146, 161,   3,  40,  51, 119,  64, 138,\n",
       "        136,  44,  78, 181,  48, 108,  92,  21, 102,  22, 104, 186,  94, 165,\n",
       "          0, 128, 167,  36, 160, 156,  11,  31, 106,  50,  34,  24,  72, 164,\n",
       "        184, 172, 116, 149,   7,  73, 141, 151,  96,  97,  56,  65,   4,  71,\n",
       "         75,  45,  91, 191,  10,  35,  54, 137,  13, 118, 115,  38,  58, 168,\n",
       "         89,   8, 109,  43, 131, 142, 163, 150,  12,  55, 105, 188,  32,  87,\n",
       "         59,  85,  19, 111,   5, 162,   2, 135,  42,  23, 130]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tensor.squeeze().sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a28f9b26-2667-47bf-9284-cf143d57dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "  \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "  try:\n",
    "      encoding = tiktoken.encoding_for_model(model)\n",
    "  except KeyError:\n",
    "      encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "  if model == \"gpt-3.5-turbo-0613\":  # note: future models may deviate from this\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "          for key, value in message.items():\n",
    "              num_tokens += len(encoding.encode(value))\n",
    "              if key == \"name\":  # if there's a name, the role is omitted\n",
    "                  num_tokens += -1  # role is always required and always 1 token\n",
    "      num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "      return num_tokens\n",
    "  else:\n",
    "      raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "12e88492-5df0-4e78-9137-a1fd7bf4f4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 prompt tokens counted.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant that translates corporate jargon into plain English.\"},\n",
    "  {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
    "  {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
    "  {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
    "  {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
    "]\n",
    "\n",
    "model = \"gpt-3.5-turbo-0613\"\n",
    "\n",
    "print(f\"{num_tokens_from_messages(messages, model)} prompt tokens counted.\")\n",
    "# Should show ~126 total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1d43612b-4505-4c2d-8436-3e54f9fe4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm.llm_utils import load_azure_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b47b3ac6-b014-4e9f-a630-e2c9d93d537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = load_azure_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4e10ee31-c0cf-4d00-9a48-08be556fb4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ae6e4c16-9317-48ac-b9a3-a4c25a84cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model='gpt-3.5-turbo-0125', messages=messages, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d6787e0d-a6ad-4303-8098-21197bf113e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cd31305a-b707-4878-8a33-590753a39ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage.prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b65f9-bfbc-4ae1-a7a0-e3f93c2b5d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
