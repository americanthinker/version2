{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40a21504-0b5f-4e74-95c8-d7b2f749f66b",
   "metadata": {},
   "source": [
    "# Fine-Tuning an Embedding Model\n",
    "***\n",
    "\n",
    "### Fine-tune Walkthrough\n",
    "\n",
    "1. Get baseline retrieval scores (vector Hit Rate, MRR, and total misses) using out-of-the-box baseline model.  You won't know objectively if fine-tuning had any effect if you don't measure the baseline results first.  I know this goes without saying it, but practitioners sometimes want to jump straight into model improvement without first considering their starting point.\n",
    "2. Collect a training and validation dataset.  This step has already been completed for you, courtesy of `gpt-3.5-turbo`.  LlamaIndex has a great out-of-the-box solution for generating query/context embedding pairs, but it isn't exactly plug and play, so I had to rewrite the function to achieve comptability for our course.  The training dataset consists of queries generated by the LLM that can be answered from the associated context (text chunk).  These pairs were generated using a prompt specifically written for the Impact Theory corpus so the training and validation data (for the most part) are high quality and contextually relevant. \n",
    "3. Instantiate a `SentenceTransformersFinetuneEngine` Class written by LlamaIndex which does a great job of abstracting away most of the details invovled in fine-tuning a Sentence Transformer model.\n",
    "4. Fit the model and set a path where the new model will reside.  I creaed a `models/` directory in the course repo, and included the directory in the `.gitignore` file so that models aren't being pushed with every commit.\n",
    "5. Create a new dataset (as you learned in Notebook 1) but this time create the embeddings using the new fine-tuned model.\n",
    "6. Create a new index on Weaviate using the new dataset you just created.\n",
    "7. Run the `retrieval_evaluation` function again, but this time instantiate your Weaviate client with the new fine-tuned model, but hold all other parameters constant (i.e. don't change any other parameter from the baseline run).\n",
    "8. Compare the fine-tuned retrieval results to the baseline results ðŸ¥³\n",
    "\n",
    "### Import Training + Valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78b81c-2019-4316-8d59-574c91ac9c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = './data/training_data_300.json'\n",
    "valid_path = './data/validation_data_100.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e8b792-8856-4ca7-a2d3-f6d196d926c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = EmbeddingQAFinetuneDataset.from_json(training_path)\n",
    "valid_set = EmbeddingQAFinetuneDataset.from_json(valid_path)\n",
    "num_training_examples = len(training_set.queries)\n",
    "num_valid_examples = len(valid_set.queries)\n",
    "print(f'# Training Samples: {num_training_examples}\\n# Validation Samples: {num_valid_examples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef4046-6622-43fe-a89d-d94f14fa9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#always a good idea to name your fine-tuned so that you can easily identify it,\n",
    "#especially if you plan on doing multiple training runs with different params\n",
    "#also probably a good idea to include the # of training samples you are using in the name\n",
    "\n",
    "model_id = client.model_name_or_path\n",
    "model_ext = model_id.split('/')[1]\n",
    "models_dir = './models'\n",
    "if not os.path.exists('./models'):\n",
    "    os.makedirs('./models') \n",
    "else:\n",
    "    print(f'{models_dir} already exists')\n",
    "ft_model_name = f'finetuned-{model_ext}-{num_training_examples}'\n",
    "model_outpath = os.path.join(models_dir, ft_model_name)\n",
    "\n",
    "print(f'Model ID: {model_id}')\n",
    "print(f'Model Outpath: {model_outpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f08636-49d5-4248-b873-20ee6ea118da",
   "metadata": {},
   "source": [
    "### Instantiate your Fine-tune engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d64e12-0279-42e7-a516-fa33f6dea68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
    "\n",
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "    training_set,\n",
    "    batch_size=32,\n",
    "    model_id=model_id,\n",
    "    model_output_path=model_outpath,\n",
    "    val_dataset=valid_set,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6368d-55e5-4f91-a21c-81b3950b6715",
   "metadata": {},
   "source": [
    "### Fit the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d8c5e5-3dcc-42b9-a81a-f60caf9f2b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc83673-ac88-47cf-ac12-d5120345a125",
   "metadata": {},
   "source": [
    "The `finetune` method will automatically generate the model directory using the `model_output_path` that you define.  Inside the directory will be a copy of the model itself (`pytorch_model.bin`) along with all the other files it needs.  Also in that folder, assuming you provide a `val_dataset` will be an evaluation report in the `eval` directory.  The evaluation report contains several IR metrics that may or may not be useful to you, but it does allow you to compare score improvements with each training epoch.  The new fine-tuned model is loaded through the `SentenceTransformer` class just like any other HuggingFace repo model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe6057-baba-4eb8-ad45-569210f34729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsa",
   "language": "python",
   "name": "vsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
