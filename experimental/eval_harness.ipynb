{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d7caf1-454d-4df6-a561-8169397fe6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d44c3272-54d4-4b6e-be25-1f8f76ac7034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.metrics import FaithfulnessMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval import evaluate\n",
    "from deepeval.models import DeepEvalBaseLLM\n",
    "from src.evaluation.llm_evaluation import (CustomAzureOpenAI, AnswerCorrectnessMetric, EvalResponse, load_eval_response) #, TestCaseBundle)\n",
    "from src.database.weaviate_interface_v4 import WeaviateWCS\n",
    "from src.database.database_utils import get_weaviate_client\n",
    "from src.preprocessor.preprocessing import FileIO\n",
    "from src.reranker import ReRanker\n",
    "from src.llm.prompt_templates import context_block, create_context_blocks\n",
    "from src.llm.llm_interface import LLM\n",
    "from src.llm.llm_utils import load_azure_openai\n",
    "from src.llm.prompt_templates import (huberman_system_message, question_answering_prompt_series,\n",
    "                                     create_context_blocks, generate_prompt_series)\n",
    "from litellm import model_cost\n",
    "\n",
    "from loguru import logger\n",
    "from random import sample\n",
    "from tqdm import tqdm\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "027d09dd-45d7-4174-8f59-1ec30ac4f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sortable_model_cost(model_cost_dict: dict) -> list[dict]:\n",
    "    '''\n",
    "    Converts a dict of dicts into a list of dicts of model names \n",
    "    and their metadata.  Only return models with an \n",
    "    'input_cost_per_token' key\n",
    "    '''\n",
    "    sortable = []\n",
    "    for k,v in model_cost_dict.items():\n",
    "        model_dict = {'model': k}\n",
    "        if 'input_cost_per_token' in v:\n",
    "            sortable.append({**model_dict, **v})\n",
    "    return sortable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa298cb7-c65c-4d99-b417-bfc74006fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_sortable_model_cost(model_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda2020-5a6b-4514-86a6-880afa9cd8b4",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "131066a0-9471-4199-a683-954fd4a773f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/golden_datasets/golden_256.json'\n",
    "data = FileIO().load_json(data_path)\n",
    "queries = list(data['queries'].values())\n",
    "\n",
    "#get random set of questions for eavl\n",
    "random_questions = sample(queries, k=25)\n",
    "assert len(random_questions) == len(set(random_questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ef34f1-e110-40ea-8789-b77859f5ea1c",
   "metadata": {},
   "source": [
    "### Set System Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc46f6f8-4413-40f5-934d-a7564a64b422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/vsa/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "client = get_weaviate_client()\n",
    "collection_name = 'Huberman_minilm_256'\n",
    "reranker= ReRanker()\n",
    "llm = load_azure_openai()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b6ba4a-899b-4676-817a-17395664ab6c",
   "metadata": {},
   "source": [
    "### Set Eval Model and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc5bb67-fd2c-4530-9ba1-109023fac080",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_eval_model = CustomAzureOpenAI('gpt-4')\n",
    "acm = AnswerCorrectnessMetric(model=azure_eval_model, strict=False).get_metric()\n",
    "faith = FaithfulnessMetric(model=azure_eval_model)\n",
    "# metrics = [AnswerCorrectnessMetric(model=azure_eval_model, strict=False).get_metric(), FaithfulnessMetric(threshold=0.7, model=azure_eval_model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "26ce50d4-7428-4810-962e-b268bbf66cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cohere': ['command-r', 'command-r-plus'],\n",
       " 'anthropic': ['claude-3-haiku-20240307',\n",
       "  'claude-3-sonnet-2024022',\n",
       "  'claude-3-opus-20240229'],\n",
       " 'openai': ['gpt-4-turbo-preview',\n",
       "  'gpt-4-0125-preview',\n",
       "  'gpt-4-1106-preview',\n",
       "  'gpt-4',\n",
       "  'gpt-4-0613',\n",
       "  'gpt-3.5-turbo',\n",
       "  'gpt-3.5-turbo-1106',\n",
       "  'gpt-3.5-turbo-0125']}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM.valid_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7fc61-cca4-4a55-ab4d-836f634444c4",
   "metadata": {},
   "source": [
    "### Create Test Case(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc4d1ffe-b3f7-4e2e-a63d-3900276a64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_evaluation(queries: list[str],\n",
    "                      client: WeaviateWCS,\n",
    "                      collection_name: str,\n",
    "                      llm: LLM,\n",
    "                      ) -> list[dict]:\n",
    "    '''\n",
    "    LLM Evaluation harness that given a list of queries does the following:\n",
    "       1. Retrieves relevant context and reranks\n",
    "       2. Generates evaluated LLM actual output\n",
    "       3. Creates retrieval context for test case\n",
    "       4. Creates a text case on the fly\n",
    "       5. Given a metric execute metric evaluation\n",
    "       6. Returns list of metric evaluations\n",
    "    '''\n",
    "\n",
    "    eval_results = []\n",
    "    for query in tqdm(queries):\n",
    "        try:\n",
    "            result = client.hybrid_search(query, collection_name, limit=200)\n",
    "            reranked = reranker.rerank(result, query, top_k=3)\n",
    "            user_message = generate_prompt_series(query, reranked)\n",
    "            actual_output = llm.chat_completion(huberman_system_message, user_message, temperature=1.0)\n",
    "            retrieval_context = create_context_blocks(reranked)\n",
    "            test_case = LLMTestCase(input=query, actual_output=actual_output, retrieval_context=retrieval_context)\n",
    "            metric.measure(test_case)\n",
    "            # logger.info(test_case.input)\n",
    "            response = EvalResponse(metric=metric,\n",
    "                                    eval_model=metric.evaluation_model,\n",
    "                                    input=test_case.input,\n",
    "                                    actual_output=test_case.actual_output,\n",
    "                                    retrieval_context=test_case.retrieval_context,\n",
    "                                    score=metric.score,\n",
    "                                    reason=metric.reason\n",
    "                                    cost=metric.evaluation_cost,\n",
    "                                    eval_steps=metric.evaluation_steps)\n",
    "            eval_results.append(response)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ded51a28-a5d6-42a4-8545-774ecd77211f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# eval_results = system_evaluation(random_questions[:5], client, collection_name, llm,faith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f19b43f-7d9d-4157-840d-915eaca40fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.llm_evaluation import EvaluationUtilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "375642db-1c9e-4bfe-9823-402bdc7925f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = EvaluationUtilties(llm, client, reranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fabfac5-abf4-4288-855c-83650729d97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUERIES: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.80it/s]\n",
      "RERANKING: 100%|███████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.62it/s]\n",
      "LLM CALLS: 100%|███████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 34.74it/s]\n"
     ]
    }
   ],
   "source": [
    "atest_cases = await eu.acreate_test_cases(queries, 'Huberman_minilm_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "02563862-1e64-45f2-a980-663a6b08265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_cases(queries: list[str],\n",
    "                      client: WeaviateWCS,\n",
    "                      collection_name: str,\n",
    "                      llm: LLM,\n",
    "                      ) -> list[LLMTestCase]:\n",
    "    '''\n",
    "    Creates a list of LLM Test Cases based on query retrievals. \n",
    "    '''\n",
    "    results = [client.hybrid_search(query, collection_name, limit=25) for query in tqdm(queries, 'QUERIES')]\n",
    "    reranked = [reranker.rerank(result, queries[i], top_k=3) for i, result in enumerate(tqdm(results, 'RERANKING'))]\n",
    "    user_messages = [generate_prompt_series(queries[i], rerank) for i, rerank in enumerate(reranked)]\n",
    "    actual_outputs = [llm.chat_completion(huberman_system_message, user_message, temperature=1.0) for\n",
    "                      user_message in tqdm(user_messages, 'LLM Calls')]\n",
    "    retrieval_contexts = [create_context_blocks(rerank) for rerank in reranked]\n",
    "    test_cases = [LLMTestCase(input=input, actual_output=output, retrieval_context=context) \\\n",
    "                  for input, output, context in list(zip(queries, actual_outputs, retrieval_contexts))]\n",
    "    return test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c9f953b0-083a-4026-a1b4-75d9ea7de765",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def asingle_eval_call(test_case: LLMTestCase,\n",
    "                            model: str | DeepEvalBaseLLM\n",
    "                            ) -> EvalResponse:\n",
    "    metric = AnswerCorrectnessMetric(model=model)\n",
    "    await metric.a_measure(test_case)\n",
    "    response = load_eval_response(metric, test_case)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a8a1275-2c41-405c-bf51-17646fcb68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def asystem_evaluation(test_cases: list[LLMTestCase],\n",
    "                             model: str | DeepEvalBaseLLM\n",
    "                            ) -> list[EvalResponse]:\n",
    "    tasks = [asingle_eval_call(case, model) for case in test_cases]\n",
    "    responses = await tqdm_asyncio.gather(*tasks)\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bdcff61a-85b5-46f6-b313-7c0900b3d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure = CustomAzureOpenAI('gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55f41085-ed36-4ff1-8caf-c11df3190beb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">sys:1: ResourceWarning: Unclosed socket &lt;zmq.Socket(zmq.PUSH) at 0x7efc105c36a0&gt;\n",
       "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
       "</pre>\n"
      ],
      "text/plain": [
       "sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7efc105c36a0>\n",
       "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████                                                                                           | 1/10 [00:04<00:36,  4.09s/it]sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7efbc165c040>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████████▏                                                                                | 2/10 [00:04<00:14,  1.85s/it]sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7efbc165d4e0>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████████▎                                                                      | 3/10 [00:04<00:08,  1.17s/it]sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7efc105c3820>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7efbc165c640>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████████▌                                        | 6/10 [00:06<00:02,  1.42it/s]sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7efbc165c5e0>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████████▋                              | 7/10 [00:06<00:01,  1.84it/s]sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7efc105c3040>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████▉          | 9/10 [00:06<00:00,  2.50it/s]sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7efc105c2980>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "responses = await asystem_evaluation(atest_cases[:10], azure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc512670-ed14-43d9-937f-4873e39e7fe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (2597890445.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[81], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    ) -> dict\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "async def polling_evaluation(test_cases: list[LLMTestCase],\n",
    "                             models: list[str | DeepEvalBaseLLM]\n",
    "                            ) -> dict:\n",
    "    results_dict = {}\n",
    "    for model in models:\n",
    "        model_name = model if isinstance(model, str) else model.model\n",
    "        model_results = await asystem_evaluation(test_cases, model)\n",
    "        scores = [r.score for r in model_results]\n",
    "        results_dict[model_name] = {'results': model_results, 'scores': scores}\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31c96c3d-587b-4b17-a425-9557d7f482c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azure.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e83c3fa-0a2d-453f-a0f6-e4c096f1ecc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be70ead-025d-444d-8e06-9f14c6723ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a09786-7097-431f-a74c-6b0700f0a836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f866d3-af32-4f87-b187-d6e54f283422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3bf738-14a9-4c12-a4c5-fd58626e0a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ba4c63b7-525a-4cd2-9c3c-789e9fc37c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(data: list[tuple]):\n",
    "    for atuple in data:\n",
    "        print(f'SCORE: {atuple[0]}')\n",
    "        reason = atuple[1][:25]\n",
    "        print(f'REASON: {reason}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0733c5c8-a0c2-4a99-a57a-2a1ed5d74839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.9347887500708539\n",
      "REASON: The actual output provide\n",
      "\n",
      "SCORE: 0.8140108828118768\n",
      "REASON: The actual output success\n",
      "\n",
      "SCORE: 0.8073533432458813\n",
      "REASON: The output accurately ref\n",
      "\n",
      "SCORE: 0.8776524051199395\n",
      "REASON: The actual output aligns \n",
      "\n",
      "SCORE: 0.7873294138077769\n",
      "REASON: The actual output effecti\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(scorereasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "83cba6a9-359e-4c08-a269-17f0339de870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The actual output provides a factual and relevant response by specifying the website and discount available for the supplements discussed on the Huberman Lab Podcast, aligning well with the retrieval context. It addresses the information requirement directly and succinctly, although it could have elaborated slightly more on the types of supplements or specific episodes that discuss them for enhanced completeness.',\n",
       " 'The actual output successfully aligns with the retrieval context, particularly emphasizing the role of the anterior mid-singulate cortex and the engagement in challenging activities that are pivotal for maintaining cognitive functions akin to those of younger individuals. However, it could have included more detailed examples or specific protocols mentioned in the retrieval context to enhance comprehensiveness.',\n",
       " 'The output accurately reflects the information from the retrieval context regarding the impact of metabolites and lactate pathways on brain function, specifically linking to brain fog and lack of focus due to excessive probiotic intake. It effectively addresses the query by summarizing the relevant scientific insights, though it could slightly enhance the specificity by citing the studies or providing a bit more detail on the mechanisms.',\n",
       " 'The actual output aligns closely with the retrieval context, accurately summarizing and simplifying the detailed explanation of how REM sleep processes emotional events and irrelevant meanings, thus reflecting a high level of factual accuracy and relevance to the input question. However, it could have included a brief mention of the mechanisms like EMDR or ketamine therapy discussed in the context, to enhance completeness.',\n",
       " \"The actual output effectively captures the essence of the political and social landscape's reflection on not setting aside egos, aligning well with the discussion themes in the retrieval context. However, it could enhance its factual accuracy by incorporating more direct references or quotes from the retrieval context to strengthen its relevance and comprehensiveness.\"]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c51239ee-be0c-4c55-b5b6-476fcbdf8b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0214"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses2[0].metric.evaluation_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b0cbf31c-40cc-4eef-922b-803df0a21505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.126"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost = [r.metric.evaluation_cost for r in responses]\n",
    "sum(total_cost)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e0fa2662-1db8-49ca-ab84-8f2e4d9b618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Compare the actual output with the retrieval context to verify factual accuracy.',\n",
       " 'Assess if the actual output effectively addresses the specific information requirement stated in the input.',\n",
       " 'Determine the comprehensiveness of the actual output in covering all key aspects mentioned in the retrieval context.',\n",
       " 'Score the actual output based on the accuracy, relevance, and completeness of the information provided between 0 and 1.']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses2[0].metric.evaluation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e1a017b7-ff50-49c4-a2ea-6dd7f766d524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'answer_correctness',\n",
       " 'evaluation_params': [<LLMTestCaseParams.INPUT: 'input'>,\n",
       "  <LLMTestCaseParams.ACTUAL_OUTPUT: 'actual_output'>,\n",
       "  <LLMTestCaseParams.RETRIEVAL_CONTEXT: 'retrieval_context'>],\n",
       " 'criteria': None,\n",
       " 'model': <deepeval.models.gpt_model.GPTModel at 0x7f9f4e7ab130>,\n",
       " 'using_native_model': True,\n",
       " 'evaluation_model': 'gpt-4-turbo',\n",
       " 'evaluation_steps': ['Compare the actual output with the retrieval context to verify factual accuracy.',\n",
       "  'Assess if the actual output effectively addresses the specific information requirement stated in the input.',\n",
       "  'Determine the comprehensiveness of the actual output in covering all key aspects mentioned in the retrieval context.',\n",
       "  'Score the actual output based on the accuracy, relevance, and completeness of the information provided between 0 and 1.'],\n",
       " '_threshold': 0.5,\n",
       " 'strict_mode': False,\n",
       " 'async_mode': True,\n",
       " 'evaluation_cost': 0.02305,\n",
       " 'reason': 'The actual output provides a factual and relevant response by specifying the website and discount available for the supplements discussed on the Huberman Lab Podcast, aligning well with the retrieval context. It addresses the information requirement directly and succinctly, although it could have elaborated slightly more on the types of supplements or specific episodes that discuss them for enhanced completeness.',\n",
       " 'score': 0.9347887500708539,\n",
       " 'success': True}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(responses2[0].metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0518b-c16a-4cf9-8fa9-2358d81978f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsa",
   "language": "python",
   "name": "vsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
